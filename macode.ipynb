{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO+pv8qNdYEZhtPwLmKY6ar",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oixchi/mathesis/blob/main/macode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRAgIP8zTr_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ef1006-ec3d-4278-bdb5-65f3647d021b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check if a GPU is available and if not, use a CPU\n",
        "device = torch.device(\n",
        "    \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"Please install GPU version of TF\")"
      ],
      "metadata": {
        "id": "2hgV3sf2UIVm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c93f32c-868d-4196-a479-2b6a6af72265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Default GPU Device: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "nUNn8iC_UKxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70247a4a-06e9-4d76-fed2-a35739ceb08a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec  2 10:13:32 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0              28W /  70W |    103MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Start time\n",
        "start_time = time.time()\n",
        "print(f\"Function call started at: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}\")\n",
        "\n",
        "# Place your code here\n",
        "time.sleep(10)  # Replace with model training process\n",
        "\n",
        "# End time\n",
        "end_time = time.time()\n",
        "print(f\"Function call ended at: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}\")\n",
        "\n",
        "# Calculate elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "elapsed_minutes = elapsed_time / 60\n",
        "\n",
        "# Print elapsed time\n",
        "print(f\"Total time taken: {elapsed_time:.2f} seconds ({elapsed_minutes:.2f} minutes)\")\n"
      ],
      "metadata": {
        "id": "6IzuvgRmUNJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "379689ae-05d8-4ea2-ef35-a8d436f55490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function call started at: 2024-12-02 10:13:36\n",
            "Function call ended at: 2024-12-02 10:13:46\n",
            "Total time taken: 10.01 seconds (0.17 minutes)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "import time\n",
        "\n",
        "device = torch.device(\n",
        "    \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "model_name= 'gpt2-large'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "model.eval()\n",
        "def generate_text(prompt, max_length=100):\n",
        "    inputs = tokenizer(prompt, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs.input_ids,\n",
        "            max_length=max_length,\n",
        "            num_return_sequences=1,\n",
        "            no_repeat_ngram_size=5,\n",
        "            early_stopping=False,\n",
        "            pad_token_id=model.config.eos_token_id,\n",
        "            attention_mask=inputs['attention_mask']\n",
        "        )\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "promptk = \"Once upon a time\"\n",
        "start_time = time.time()\n",
        "print(f\"Function call started at: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}\")\n",
        "generated_text = generate_text(promptk)\n",
        "end_time = time.time()\n",
        "print(f\"Function call ended at: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}\")\n",
        "print(\"BEGIN------------------\", generated_text, \"-------------END\")\n",
        "# Calculate elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "elapsed_minutes = elapsed_time / 60\n",
        "\n",
        "# Print elapsed time\n",
        "print(f\"Total time taken: {elapsed_time:.2f} seconds ({elapsed_minutes:.2f} minutes)\")\n"
      ],
      "metadata": {
        "id": "wj29RSYuUREG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "LdptItw1U7Nq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c262386-5b51-4f30-973f-c517bef5b80b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.26.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the pre-trained embeddings model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Define your text (a sentence or a list of sentences)\n",
        "text = [\"This is an example sentence.\", \"Embeddings convert text into vectors.\"]\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = model.encode(text)\n",
        "\n",
        "# Show the embedding for the first sentence\n",
        "print(embeddings[0])"
      ],
      "metadata": {
        "id": "LlYPQ_otU4uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "CTgFZHqAOc2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "\n",
        "# Title of the app\n",
        "st.title(\"My First Streamlit App\")\n",
        "# Text input\n",
        "name = st.text_input(\"Enter your name:\")\n",
        "# Display a greeting message\n",
        "if st.button(\"Submit\"):\n",
        "    st.write(f\"Hello, {name}! Welcome to Streamlit!\")"
      ],
      "metadata": {
        "id": "4g-0Agj3OQf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token(\"2n9kxxKgkykAbfQ0AtCbstcsSgC_2JvQe6E6f9dDbbfspXsBU\")\n",
        "\n",
        "# Create the Streamlit app\n",
        "app_code = \"\"\"\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"My Streamlit App on Google Colab\")\n",
        "\n",
        "name = st.text_input(\"Enter your name:\")\n",
        "if st.button(\"Submit\"):\n",
        "    st.write(f\"Hello, {name}!\")\n",
        "\"\"\"\n",
        "\n",
        "# Write the app to a file\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "# Set up ngrok to tunnel to port 8501\n",
        "# from pyngrok import ngrok\n",
        "public_url = ngrok.connect(\"8501\", \"http\")\n",
        "print(\"Public URL:\", public_url)\n",
        "\n",
        "\n",
        "# Run the Streamlit app\n",
        "!streamlit run app.py &>/dev/null&\n"
      ],
      "metadata": {
        "id": "FeZOx-3WPFj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ngrok.set_auth_token(\"2n9kxxKgkykAbfQ0AtCbstcsSgC_2JvQe6E6f9dDbbfspXsBU\")\n",
        "\n",
        "!killall ngrok\n",
        "\n",
        "# Create the Streamlit app\n",
        "app_code = \"\"\"\n",
        "# Create centered main title\n",
        "st.title('Ask me a question K')\n",
        "\n",
        "# Chat message storage\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "for message in st.session_state.messages:\n",
        "    st.chat_message(message[\"role\"]).markdown(message['content'])\n",
        "\n",
        "prompt = st.chat_input(\"Input your prompt here\")\n",
        "\n",
        "if prompt:\n",
        "      st.chat_message('user').markdown(prompt)\n",
        "      st.session_state.messages.append({'role':'user', 'content':prompt})\n",
        "      #response=generate_response(prompt)\n",
        "      #response = retrieve(prompt, k=3)\n",
        "      response = \"Hallo Ketli\"\n",
        "      st.chat_message('assistant').markdown(response)\n",
        "      st.session_state.messages.append({'role':'assistant', 'content':response})\n",
        "\"\"\"\n",
        "\n",
        "# Write the app to a file\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "# Set up ngrok to tunnel to port 8501\n",
        "public_url = ngrok.connect(\"8501\", \"http\")\n",
        "print(\"Public URL:\", public_url)\n",
        "\n",
        "\n",
        "# Run the Streamlit app\n",
        "!streamlit run app.py &>/dev/null&"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8unQNN90RRa_",
        "outputId": "0b124d9b-adc9-4ea7-b346-cb10d6262189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://df06-34-125-33-53.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf"
      ],
      "metadata": {
        "id": "nxyR2jYERg04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "u9s1HKxNRxM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc58a35-1640-4df8-dc54-749d7467cd1f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = 'ebrains_dataset_new.pdf'\n",
        "pdf_document = fitz.open(pdf_path)"
      ],
      "metadata": {
        "id": "_fysZmiXSwdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extract text from each page\n",
        "pdf_text = []\n",
        "for page_num in range(pdf_document.page_count):\n",
        "    page = pdf_document.load_page(page_num)\n",
        "    pdf_text.append(page.get_text())\n",
        "\n",
        "# Close the PDF document\n",
        "pdf_document.close()\n",
        "\n",
        "# Join all the extracted text into a single string or split into paragraphs/sentences\n",
        "pdf_text = \" \".join(pdf_text)"
      ],
      "metadata": {
        "id": "3pssriHFS1xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to chunk the text into manageable pieces\n",
        "def chunk_text(text, max_chunk_size=512, overlap=50):\n",
        "    sentences = nltk.sent_tokenize(text)  # Split into sentences\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_chunk_size = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence_length = len(sentence.split())\n",
        "\n",
        "        # Check if adding this sentence exceeds the max chunk size\n",
        "        if current_chunk_size + sentence_length > max_chunk_size:\n",
        "            # Append the current chunk to chunks and reset\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            # Start a new chunk with overlap\n",
        "            current_chunk = current_chunk[-overlap:]  # Keep the last few sentences for context\n",
        "            current_chunk_size = sum(len(s.split()) for s in current_chunk)\n",
        "\n",
        "        # Add the sentence to the current chunk\n",
        "        current_chunk.append(sentence)\n",
        "        current_chunk_size += sentence_length\n",
        "\n",
        "    # Add any remaining sentences as the last chunk\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# Split the text into sentences\n",
        "# documents = nltk.sent_tokenize(pdf_text)\n",
        "\n",
        "# Split the text into chunks\n",
        "documents = chunk_text(pdf_text, max_chunk_size=512, overlap=50)\n",
        "\n",
        "# Alternatively, you can split it into paragraphs\n",
        "# documents = pdf_text.split('\\n\\n')  # Split by double newlines (for paragraphs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-QhK2s0Te3r",
        "outputId": "d73d7bc2-7d9c-41a3-babb-cb22e0c6715a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained embedding model\n",
        "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Create document embeddings\n",
        "document_embeddings = embedding_model.encode(documents)\n",
        "\n",
        "# Convert the embeddings to a format suitable for FAISS\n",
        "embedding_dim = document_embeddings.shape[1]\n",
        "faiss_index = faiss.IndexFlatL2(embedding_dim)\n",
        "\n",
        "# Add the document embeddings to the index\n",
        "faiss_index.add(np.array(document_embeddings))\n",
        "\n",
        "def retrieve(query, k=5):\n",
        "    # Encode the query into a vector\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "\n",
        "    # Search FAISS index for the most relevant documents\n",
        "    distances, indices = faiss_index.search(query_embedding, k)\n",
        "    return [documents[i] for i in indices[0]]"
      ],
      "metadata": {
        "id": "Wujcs76yTfxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"what is virtual brain\"\n",
        "retrieve(prompt, k=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glM_FpaOUcJs",
        "outputId": "7b618549-7858-4f97-d0d0-b86a8585f1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NEURON’s computational engine employs special algorithms that achieve high efficiency by exploiting \\nthe structure of the equations that describe neuronal properties. It has functions that are tailored for \\nconveniently controlling simulations, and presenting the results of real neurophysiological problems \\ngraphically in ways that are quickly and intuitively grasped. Instead of forcing users to reformulate their \\nconceptual models to fit the requirements of a general purpose simulator, NEURON is designed to let \\nthem deal directly with familiar neuroscience concepts. Consequently, users can think in terms of the \\nbiophysical properties of membrane and cytoplasm, the branched architecture of neurons, and the effects\\nof synaptic communication between cells. The Virtual Brain (TVB) is an open-source platform for constructing and simulating personalised brain \\nnetwork models. The TVB-on-EBRAINS ecosystem includes a variety of prepackaged modules, \\nintegrated simulation tools, pipelines and data sets for easy and immediate use on EBRAINS. Process \\nyour large cohort databases and use these results to develop potential medical treatments, therapies or \\ndiagnostic procedures. The Virtual Brain  \\nThe Virtual Brain (TVB) is an open-source platform for constructing and simulating personalised brain \\nnetwork models. The TVB-on-EBRAINS ecosystem includes a variety of prepackaged modules, \\nintegrated simulation tools, pipelines and data sets for easy and immediate use on EBRAINS. Process \\nyour large cohort databases and use these results to develop potential medical treatments, therapies or \\ndiagnostic procedures. NEST is a simulator for spiking neural network models that focuses on the dynamics, size and structure of\\nneural systems, rather than on the exact morphology of individual neurons. It is ideal for networks of any \\nsize, including models of information processing (e.g. in the visual or auditory cortex of mammals), \\nmodels of network activity dynamics (e.g. laminar cortical networks or balanced random networks) and \\nmodels of learning and plasticity. NEST is openly available for download. NEST  \\nNEST is a simulator for spiking neural network models that focuses on the dynamics, size and structure of\\nneural systems, rather than on the exact morphology of individual neurons. It is ideal for networks of any \\nsize, including models of information processing (e.g. in the visual or auditory cortex of mammals), \\nmodels of network activity dynamics (e.g. laminar cortical networks or balanced random networks) and \\nmodels of learning and plasticity. NEST is openly available for download. NEURON’s computational engine employs special algorithms that achieve high efficiency by exploiting \\nthe structure of the equations that describe neuronal properties. It has functions that are tailored for \\nconveniently controlling simulations, and presenting the results of real neurophysiological problems \\ngraphically in ways that are quickly and intuitively grasped. Instead of forcing users to reformulate their \\nconceptual models to fit the requirements of a general purpose simulator, NEURON is designed to let \\nthem deal directly with familiar neuroscience concepts. Consequently, users can think in terms of the \\nbiophysical properties of membrane and cytoplasm, the branched architecture of neurons, and the effects\\nof synaptic communication between cells. Neuron  \\nNEURON’s computational engine employs special algorithms that achieve high efficiency by exploiting \\nthe structure of the equations that describe neuronal properties. It has functions that are tailored for \\nconveniently controlling simulations, and presenting the results of real neurophysiological problems \\ngraphically in ways that are quickly and intuitively grasped. Instead of forcing users to reformulate their \\nconceptual models to fit the requirements of a general purpose simulator, NEURON is designed to let \\nthem deal directly with familiar neuroscience concepts. Consequently, users can think in terms of the \\nbiophysical properties of membrane and cytoplasm, the branched architecture of neurons, and the effects\\nof synaptic communication between cells. News  \\nUsing EBRAINS modelling tools to investigate the relationship between brain structure and function  \\nScientists use EBRAINS to simulate deep brain stimulation in Parkinsonâ\\x00\\x00s disease  \\nHow scientists are changing the way we treat epilepsy with EBRAINS  \\nEBRAINS is open and free. Sign up now for complete access to our tools and services. EBRAINS is open and free. Sign up now for complete access to our tools and services. Make the most out of EBRAINS  \\nEBRAINS is open and free. Sign up now for complete access to our tools and services. Follow EBRAINS to keep up-to-date  \\nFollow EBRAINS to keep up-to-date  \\nFollow EBRAINS to keep up-to-date  \\nFollow EBRAINS to keep up-to-date  \\nFollow EBRAINS to keep up-to-date  \\nEBRAINS is funded by the Horizon Europe Framework Programme. EBRAINS is funded by the Horizon Europe Framework Programme. EBRAINS is funded by the Horizon Europe Framework Programme. EBRAINS is funded by the Horizon Europe Framework Programme. The formal establishment of EBRAINS BELGIUM as a consortium and an EBRAINS National Node is \\ncurrently in process. To date, UHasselt currently acts as the Full Member within Belgium. The Belgian members of EBRAINS AISBL excel in imaging/EEG analyses, atlasing, modeling and \\nsensitive data handling. Together, we strive towards laying the foundations for EBRAINS BELGIUM to \\nbecome part of a pan-European open state-of-the-art distributed Research Infrastructure (RI) that fosters \\ncollaborative brain science, opens the way to ground-breaking discovery in neuroscience, and aims to aid\\nto secure Europeâ\\x00\\x00s leading position in the dynamically growing field of multidisciplinary brain research \\nand its exploitation. Moreover, training, professional development, and community building will become \\nkey in our portfolio, since a robust, high-quality EBRAINS BELGIUM training platform will:  \\nEBRAINS BELGIUM aspires to foster interactions between all Belgian Universities, co-developing and \\nusing tools that can be used across species, including healthy humans, patients, and animals. Do you have any questions about the Belgium node? Please submit your question and email address \\nbelow. EBRAINS is open and free. Sign up now for complete access to our tools and services. Follow EBRAINS to keep up-to-date  \\nEBRAINS is funded by the Horizon Europe Framework Programme. The formal establishment of EBRAINS BELGIUM as a consortium and an EBRAINS National Node is \\ncurrently in process. To date, UHasselt currently acts as the Full Member within Belgium. The Belgian members of EBRAINS AISBL excel in imaging/EEG analyses, atlasing, modeling and \\nsensitive data handling.']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "def get_ebrains_links(base_url):\n",
        "    response = requests.get(base_url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    all_links = soup.find_all('a', href=True)\n",
        "    filtered_links = []\n",
        "\n",
        "    for link in all_links:\n",
        "        href = link['href']\n",
        "        full_url = urljoin(base_url, href)\n",
        "        if 'ebrains.eu' in full_url:\n",
        "            filtered_links.append(full_url)\n",
        "    unique_links = list(set(filtered_links))\n",
        "    return unique_links\n",
        "\n",
        "base_url = 'https://www.ebrains.eu/'\n",
        "ebrains_links = sorted(get_ebrains_links(base_url))\n",
        "print(ebrains_links)\n",
        "\n",
        "for link in ebrains_links:\n",
        "    print(get_ebrains_links(link))\n",
        "\n"
      ],
      "metadata": {
        "id": "eaVfdJEgax9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "def get_ebrains_links(base_url):\n",
        "    response = requests.get(base_url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    all_links = soup.find_all('a', href=True)\n",
        "\n",
        "    # Use list comprehension to filter and process links\n",
        "    filtered_links = [urljoin(base_url, link['href']) for link in all_links if 'ebrains.eu' in urljoin(base_url, link['href'])]\n",
        "\n",
        "    # Remove duplicates using set, then sort the list\n",
        "    unique_links = sorted(list(set(filtered_links)))\n",
        "    return unique_links\n",
        "\n",
        "base_url = 'https://www.ebrains.eu/'\n",
        "\n",
        "# Get all the links from the base URL\n",
        "ebrains_links = get_ebrains_links(base_url)\n",
        "\n",
        "# Create a combined list and ensure uniqueness across all links\n",
        "all_links = set(ebrains_links)  # Use a set to start with unique base links\n",
        "\n",
        "# Gather links from all individual pages and update the set\n",
        "for link in ebrains_links:\n",
        "    page_links = get_ebrains_links(link)\n",
        "    all_links.update(page_links)  # Add new links to the set, ensuring uniqueness\n",
        "\n",
        "# Convert set back to a list and sort it\n",
        "all_links = sorted(list(all_links))\n",
        "\n",
        "# Print each link with a line break\n",
        "for link in all_links:\n",
        "    print(link)\n",
        "    print()  # Print a blank line for separation\n"
      ],
      "metadata": {
        "id": "ls0kCpZEeKGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "def gather_all_ebrains_links(base_url):\n",
        "    # Function to gather and return all unique links from a base URL and its linked pages\n",
        "    def get_ebrains_links(url):\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        all_links = soup.find_all('a', href=True)\n",
        "\n",
        "        # Use list comprehension to filter and process links\n",
        "        filtered_links = [urljoin(url, link['href']) for link in all_links if 'ebrains.eu' in urljoin(url, link['href'])]\n",
        "\n",
        "        # Remove duplicates using set, then sort the list\n",
        "        unique_links = sorted(list(set(filtered_links)))\n",
        "        return unique_links\n",
        "\n",
        "    # Get all the links from the base URL\n",
        "    ebrains_links = get_ebrains_links(base_url)\n",
        "\n",
        "    # Create a combined list and ensure uniqueness across all links\n",
        "    all_links = set(ebrains_links)  # Use a set to start with unique base links\n",
        "\n",
        "    # Gather links from all individual pages and update the set\n",
        "    for link in ebrains_links:\n",
        "        page_links = get_ebrains_links(link)\n",
        "        all_links.update(page_links)  # Add new links to the set, ensuring uniqueness\n",
        "\n",
        "    # Convert set back to a list and sort it\n",
        "    return sorted(list(all_links))\n",
        "\n",
        "# Call the function and print the results\n",
        "base_url = 'https://www.ebrains.eu/'\n",
        "all_ebrains_links = gather_all_ebrains_links(base_url)\n",
        "all_ebrains_links_without_pdf = [link for link in all_ebrains_links if not link.endswith('.pdf') and '@' not in link]\n",
        "# pdf can be used\n",
        "all_ebrains_links_with_pdf = [link for link in all_ebrains_links if link.endswith('.pdf')]\n",
        "\n",
        "print(len(all_ebrains_links_without_pdf))\n",
        "print(len(all_ebrains_links_with_pdf))\n",
        "\n",
        "\n",
        "for link in all_ebrains_links_without_pdf:\n",
        "  print(link)\n",
        "print(\"---------------\")\n",
        "for link in all_ebrains_links_with_pdf:\n",
        "  print(link)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzvtElorfx1w",
        "outputId": "5bf1f599-b800-41c0-f347-01b985090872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186\n",
            "25\n",
            "http://www.ebrains.eu\n",
            "https://atlases.ebrains.eu/viewer\n",
            "https://community.ebrains.eu/\n",
            "https://community.ebrains.eu/_communities/-MyqcYuqL557zIUB19Fq/about\n",
            "https://drive.ebrains.eu/d/dc0b712dbe1245499b4e/\n",
            "https://iam.ebrains.eu/register\n",
            "https://search.kg.ebrains.eu/\n",
            "https://search.kg.ebrains.eu/instances/0b219bf1-dead-4a06-811a-fdce66f2ec7d\n",
            "https://search.kg.ebrains.eu/instances/cc17c126-dec2-486c-a23d-deedf9102269\n",
            "https://search.kg.ebrains.eu/instances/d69b70e2-3002-4eaf-9c61-9c56f019bbc8\n",
            "https://search.kg.ebrains.eu/instances/e1267b8b-96ec-4759-acb4-2d8ffc23f524\n",
            "https://wiki.ebrains.eu/bin/view/Collabs/documentation\n",
            "https://wiki.ebrains.eu/bin/view/Collabs/documentation/tutorials/\n",
            "https://www.ebrains.eu/\n",
            "https://www.ebrains.eu/about\n",
            "https://www.ebrains.eu/about#national-nodes\n",
            "https://www.ebrains.eu/about#roadmap\n",
            "https://www.ebrains.eu/about#vision\n",
            "https://www.ebrains.eu/brain-atlases/analysis\n",
            "https://www.ebrains.eu/brain-atlases/analysis/atlas-driven-analysis-resources\n",
            "https://www.ebrains.eu/brain-atlases/analysis/gene-expression-analysis-in-human-brain-atlas-regions\n",
            "https://www.ebrains.eu/brain-atlases/analysis/image-annotation-and-export-of-coordinate-points\n",
            "https://www.ebrains.eu/brain-atlases/analysis/labelled-features-analysis\n",
            "https://www.ebrains.eu/brain-atlases/apis\n",
            "https://www.ebrains.eu/brain-atlases/apis/http-api\n",
            "https://www.ebrains.eu/brain-atlases/apis/python-client\n",
            "https://www.ebrains.eu/brain-atlases/collaboratory-2\n",
            "https://www.ebrains.eu/brain-atlases/collaboratory-2/learn-more-305\n",
            "https://www.ebrains.eu/brain-atlases/computing-132\n",
            "https://www.ebrains.eu/brain-atlases/computing-132/high-performance-computing-325\n",
            "https://www.ebrains.eu/brain-atlases/computing-132/neuromorphic-computing-324\n",
            "https://www.ebrains.eu/brain-atlases/data-integration\n",
            "https://www.ebrains.eu/brain-atlases/data-integration/2d-sections\n",
            "https://www.ebrains.eu/brain-atlases/data-integration/data-integration-resources\n",
            "https://www.ebrains.eu/brain-atlases/data-integration/data-integration-tools\n",
            "https://www.ebrains.eu/brain-atlases/data-integration/histological-volumes\n",
            "https://www.ebrains.eu/brain-atlases/data-integration/human-mri-volumes\n",
            "https://www.ebrains.eu/brain-atlases/reference-atlases\n",
            "https://www.ebrains.eu/brain-atlases/reference-atlases/brain-atlas-resources\n",
            "https://www.ebrains.eu/brain-atlases/reference-atlases/human-brain\n",
            "https://www.ebrains.eu/brain-atlases/reference-atlases/monkey-brain\n",
            "https://www.ebrains.eu/brain-atlases/reference-atlases/mouse-brain\n",
            "https://www.ebrains.eu/brain-atlases/reference-atlases/rat-brain\n",
            "https://www.ebrains.eu/contact\n",
            "https://www.ebrains.eu/data/collaboratory\n",
            "https://www.ebrains.eu/data/collaboratory/learn-more-303\n",
            "https://www.ebrains.eu/data/computing-3\n",
            "https://www.ebrains.eu/data/computing-3/high-performance-computing-3\n",
            "https://www.ebrains.eu/data/computing-3/neuromorphic-computing-322\n",
            "https://www.ebrains.eu/data/find-data\n",
            "https://www.ebrains.eu/data/find-data/find-data\n",
            "https://www.ebrains.eu/data/live-papers\n",
            "https://www.ebrains.eu/data/live-papers/live-papers\n",
            "https://www.ebrains.eu/data/share-data\n",
            "https://www.ebrains.eu/data/share-data/share-data-process\n",
            "https://www.ebrains.eu/focus-areas\n",
            "https://www.ebrains.eu/focus-areas#accelerating-brain-research-and-innovation\n",
            "https://www.ebrains.eu/focus-areas#making-brain-health-a-public-health-priority\n",
            "https://www.ebrains.eu/focus-areas#translating-brain-knowledge-into-technological-advances\n",
            "https://www.ebrains.eu/health-research-platforms/collaboratory-124\n",
            "https://www.ebrains.eu/health-research-platforms/collaboratory-124/learn-more-309\n",
            "https://www.ebrains.eu/health-research-platforms/computing-133\n",
            "https://www.ebrains.eu/health-research-platforms/computing-133/high-performance-computing-327\n",
            "https://www.ebrains.eu/health-research-platforms/computing-133/neuromorphic-computing-326\n",
            "https://www.ebrains.eu/health-research-platforms/health-platforms\n",
            "https://www.ebrains.eu/health-research-platforms/health-platforms/find-store-and-share-data-2\n",
            "https://www.ebrains.eu/health-research-platforms/health-platforms/work-with-health-data-2\n",
            "https://www.ebrains.eu/modelling-simulation-and-computing/collaboratory-3\n",
            "https://www.ebrains.eu/modelling-simulation-and-computing/collaboratory-3/learn-more-307\n",
            "https://www.ebrains.eu/modelling-simulation-and-computing/computing\n",
            "https://www.ebrains.eu/modelling-simulation-and-computing/computing/high-performance-computing\n",
            "https://www.ebrains.eu/modelling-simulation-and-computing/computing/neuromorphic-computing\n",
            "https://www.ebrains.eu/modelling-simulation-and-computing/simulation\n",
            "https://www.ebrains.eu/modelling-simulation-and-computing/simulation/cellular-simulation\n",
            "https://www.ebrains.eu/modelling-simulation-and-computing/simulation/learn-more-3\n",
            "https://www.ebrains.eu/modelling-simulation-and-computing/simulation/molecular-and-subcellular-simulation\n",
            "https://www.ebrains.eu/modelling-simulation-and-computing/simulation/network-simulation\n",
            "https://www.ebrains.eu/modelling-simulation-and-computing/simulation/neuromorphic-computing-3\n",
            "https://www.ebrains.eu/modelling-simulation-and-computing/simulation/simulation-tools\n",
            "https://www.ebrains.eu/modelling-simulation-and-computing/simulation/whole-brain-simulation-2\n",
            "https://www.ebrains.eu/modelling-simulation-and-computing/visualisation\n",
            "https://www.ebrains.eu/modelling-simulation-and-computing/visualisation/analysis-and-visualisation\n",
            "https://www.ebrains.eu/national-nodes\n",
            "https://www.ebrains.eu/national-nodes/belgium\n",
            "https://www.ebrains.eu/national-nodes/denmark\n",
            "https://www.ebrains.eu/national-nodes/france\n",
            "https://www.ebrains.eu/national-nodes/germany\n",
            "https://www.ebrains.eu/national-nodes/greece\n",
            "https://www.ebrains.eu/national-nodes/italy\n",
            "https://www.ebrains.eu/national-nodes/netherlands\n",
            "https://www.ebrains.eu/national-nodes/norway\n",
            "https://www.ebrains.eu/national-nodes/spain\n",
            "https://www.ebrains.eu/national-nodes/sweden\n",
            "https://www.ebrains.eu/national-nodes/switzerland\n",
            "https://www.ebrains.eu/news-and-events\n",
            "https://www.ebrains.eu/news-and-events/1st-esd-hackathon\n",
            "https://www.ebrains.eu/news-and-events/addressing-the-mental-health-crisis-with-personalised-treatment-the-launch-of-the-virtual-brain-twin-project\n",
            "https://www.ebrains.eu/news-and-events/advanced-neural-data-analysis-and-neuroinformatics-school\n",
            "https://www.ebrains.eu/news-and-events/advancing-computational-neuroscience-ebrains-germany-at-the-bernstein-conference-2024\n",
            "https://www.ebrains.eu/news-and-events/brain-innovation-days-2024\n",
            "https://www.ebrains.eu/news-and-events/comment-in-nature-reviews-whole-brain-modelling-as-an-essential-tool-for-neuroscientists\n",
            "https://www.ebrains.eu/news-and-events/complete-data-package-of-julich-brain-atlas-released\n",
            "https://www.ebrains.eu/news-and-events/design-co-lab-within-the-virtual-brain-twin-project\n",
            "https://www.ebrains.eu/news-and-events/ebrain-health-project-awarded-funding-by-horizon-europe\n",
            "https://www.ebrains.eu/news-and-events/ebrains-at-the-future-of-brain-health-clinically-informed-and-patient-centered-brain-research-event\n",
            "https://www.ebrains.eu/news-and-events/ebrains-brain-atlas-enables-researchers-to-gain-a-deeper-understanding-of-brain-organization\n",
            "https://www.ebrains.eu/news-and-events/ebrains-contributes-to-who-position-paper-on-brain-health\n",
            "https://www.ebrains.eu/news-and-events/ebrains-germany-established\n",
            "https://www.ebrains.eu/news-and-events/ebrains-healthdatacloud-tackling-the-sensitive-data-challenge-in-brain-research\n",
            "https://www.ebrains.eu/news-and-events/ebrains-meets-with-neuroinformatics-community-at-incf-assembly-2024\n",
            "https://www.ebrains.eu/news-and-events/eitn-ebrains-fall-school-in-computational-neuroscience\n",
            "https://www.ebrains.eu/news-and-events/erice-2024-modelling-the-brain-in-health-and-disease-theory-and-applications-of-digital-twins\n",
            "https://www.ebrains.eu/news-and-events/hands-on-brainscales-tutorial-at-the-european-institute-for-neuromorphic-computing\n",
            "https://www.ebrains.eu/news-and-events/hands-on-spinnaker-tutorial-at-the-european-institute-for-neuromorphic-computing\n",
            "https://www.ebrains.eu/news-and-events/how-scientists-are-changing-the-way-we-treat-epilepsy-with-ebrains\n",
            "https://www.ebrains.eu/news-and-events/human-motor-circuits-interdisciplinary-meeting-of-the-spanish-ebrains-node\n",
            "https://www.ebrains.eu/news-and-events/independent-expert-report-the-human-brain-project-significantly-advanced-neuroscience\n",
            "https://www.ebrains.eu/news-and-events/new-release-of-the-julich-brain-atlas-adds-52-new-maps\n",
            "https://www.ebrains.eu/news-and-events/new-unified-mouse-atlas-from-the-kim-lab-is-now-available-in-the-ebrains-quicknii-image-registration-tool\n",
            "https://www.ebrains.eu/news-and-events/next-level-community-building-for-ebrains\n",
            "https://www.ebrains.eu/news-and-events/open-call-announcement-funding-opportunity-for-data-integration-into-ebrains-2-0\n",
            "https://www.ebrains.eu/news-and-events/scientists-use-ebrains-to-simulate-deep-brain-stimulation-in-parkinson-s-disease\n",
            "https://www.ebrains.eu/news-and-events/using-ebrains-modelling-tools-to-investigate-the-relationship-between-brain-structure-and-function-2\n",
            "https://www.ebrains.eu/news-and-events?category=collaboration\n",
            "https://www.ebrains.eu/news-and-events?category=event\n",
            "https://www.ebrains.eu/news-and-events?category=news\n",
            "https://www.ebrains.eu/news-and-events?category=people\n",
            "https://www.ebrains.eu/news-and-events?category=policy\n",
            "https://www.ebrains.eu/news-and-events?category=press-release\n",
            "https://www.ebrains.eu/news-and-events?category=science-and-technology\n",
            "https://www.ebrains.eu/news-and-events?category=upcoming-event\n",
            "https://www.ebrains.eu/news-and-events?category=update\n",
            "https://www.ebrains.eu/news-and-events?page=1\n",
            "https://www.ebrains.eu/news-and-events?page=2\n",
            "https://www.ebrains.eu/news-and-events?page=21\n",
            "https://www.ebrains.eu/news-and-events?page=3\n",
            "https://www.ebrains.eu/page/annual-reports\n",
            "https://www.ebrains.eu/page/careers\n",
            "https://www.ebrains.eu/page/discover-ebrains\n",
            "https://www.ebrains.eu/page/education-and-training\n",
            "https://www.ebrains.eu/page/ethics-and-society-vision\n",
            "https://www.ebrains.eu/page/gender-and-equality\n",
            "https://www.ebrains.eu/page/membership\n",
            "https://www.ebrains.eu/page/newsletter\n",
            "https://www.ebrains.eu/page/open-calls\n",
            "https://www.ebrains.eu/page/procurement\n",
            "https://www.ebrains.eu/page/science-vision\n",
            "https://www.ebrains.eu/page/sign-up\n",
            "https://www.ebrains.eu/page/terms-and-policies\n",
            "https://www.ebrains.eu/projects\n",
            "https://www.ebrains.eu/projects/aisn\n",
            "https://www.ebrains.eu/projects/csa-brainhealth\n",
            "https://www.ebrains.eu/projects/ddf\n",
            "https://www.ebrains.eu/projects/ebrain-health\n",
            "https://www.ebrains.eu/projects/ebrains-2-0\n",
            "https://www.ebrains.eu/projects/ebrains-prep\n",
            "https://www.ebrains.eu/projects/ehds\n",
            "https://www.ebrains.eu/projects/greendigit\n",
            "https://www.ebrains.eu/projects/integrate-lmedc\n",
            "https://www.ebrains.eu/projects/phrase\n",
            "https://www.ebrains.eu/projects/tef-health\n",
            "https://www.ebrains.eu/projects/virtual-brain-twin-for-personalized-treatment-of-psychiatric-disorders\n",
            "https://www.ebrains.eu/projects/who\n",
            "https://www.ebrains.eu/resources\n",
            "https://www.ebrains.eu/tools\n",
            "https://www.ebrains.eu/tools/cobrawap\n",
            "https://www.ebrains.eu/tools/elephant\n",
            "https://www.ebrains.eu/tools/frites-framework-for-information-theoretical-analysis-of-electrophysiological-data-and-statistics\n",
            "https://www.ebrains.eu/tools/healthdatacloud\n",
            "https://www.ebrains.eu/tools/human-brain-atlas\n",
            "https://www.ebrains.eu/tools/human-intracerebral-eeg-platform\n",
            "https://www.ebrains.eu/tools/medical-informatics-platform\n",
            "https://www.ebrains.eu/tools/mouse-brain\n",
            "https://www.ebrains.eu/tools/nest\n",
            "https://www.ebrains.eu/tools/neuron\n",
            "https://www.ebrains.eu/tools/rat-brain\n",
            "https://www.ebrains.eu/tools/spynnaker\n",
            "https://www.ebrains.eu/tools/the-virtual-brain\n",
            "https://www.ebrains.eu/tools?filter=brain-atlas\n",
            "https://www.ebrains.eu/validation-and-inference/collaboratory-122\n",
            "https://www.ebrains.eu/validation-and-inference/collaboratory-122/learn-more-308\n",
            "https://www.ebrains.eu/validation-and-inference/computing-2\n",
            "https://www.ebrains.eu/validation-and-inference/computing-2/high-performance-computing-2\n",
            "https://www.ebrains.eu/validation-and-inference/computing-2/neuromorphic-computing-2\n",
            "https://www.ebrains.eu/validation-and-inference/validation\n",
            "https://www.ebrains.eu/validation-and-inference/validation/validation-and-inference\n",
            "---------------\n",
            "https://files.ebrains.eu/file/09bd2557-5d26-43bc-aca5-3a5df25bc1c5/hbp_pioneering_digital_neuroscience.pdf\n",
            "https://files.ebrains.eu/file/1915ab0c-b800-46ca-b433-75f0e7d07dcf/ProjectCommunicationsContentOfficer-Posting.pdf\n",
            "https://files.ebrains.eu/file/1d392941-e722-4474-badd-6f811c1673fc/EBRAINS_ScientificVision_April_2023.pdf\n",
            "https://files.ebrains.eu/file/2a7a23d8-a21c-4927-8665-f530d6a31d3a/Membershipleaflet_EBRAINS_September_2024.pdf\n",
            "https://files.ebrains.eu/file/36905541-c68a-47f3-9ecc-42e36d80bce5/EBRAINS_Science_and_Technology_Commitee_To_R_e6dfe1a918.pdf\n",
            "https://files.ebrains.eu/file/3b8a3859-74e2-48a7-9882-79935c19db68/Discover_EBRAINS_2023.pdf\n",
            "https://files.ebrains.eu/file/3e7cd7a2-f9d3-4d62-9ce2-0edd81f92523/EBRAINS-Management-Board-May-2024.pdf\n",
            "https://files.ebrains.eu/file/5617e4bf-4f79-4d13-857c-c46c9d6b16a8/230413_hpb22_digital_1.pdf\n",
            "https://files.ebrains.eu/file/69456c0d-de07-495a-8c8f-d47534d95223/EBRAINS-Invitation-to-tender.pdf\n",
            "https://files.ebrains.eu/file/6c5cf3b7-5630-486e-b70e-ee062d8492c4/EBRAINS-EESC-May-2024.pdf\n",
            "https://files.ebrains.eu/file/72e3d51f-a16c-41c1-b529-aca096dabb65/EBRAINS_Ethics_and_Society_Vision_June_2022_9c012269d6.pdf\n",
            "https://files.ebrains.eu/file/80c61e27-2eb8-4343-b572-b6c60d5fa231/hbp_spotlights_achievements_2023_1.pdf\n",
            "https://files.ebrains.eu/file/82d095cb-31ae-45b7-9635-c57687f03735/Gender_Equality_Plan_26012022_v1_71ccaa45a7.pdf\n",
            "https://files.ebrains.eu/file/87d4c36c-3755-4242-81f8-770fcefa3d51/EBRAINS-National-Node-Board-May-2023.pdf\n",
            "https://files.ebrains.eu/file/8d2df951-7430-4f4f-be3a-4eee60db8a9c/EBRAINS_Science_and_Technology_Committee_List_of_Members_May_2023.pdf\n",
            "https://files.ebrains.eu/file/a29a2d69-bd87-4486-92a1-95a48639cb4d/EBRAINS-Governing-Board-April-2024.pdf\n",
            "https://files.ebrains.eu/file/c71b746e-8141-43ec-8b25-948ec5cd0b2b/hbp_tool_book_2023_1.pdf\n",
            "https://files.ebrains.eu/file/cab90591-f55c-4d40-a58f-2d81328a0db8/EBRAINS-Members-24-June-2024.pdf\n",
            "https://files.ebrains.eu/file/e46b8b1c-4a0e-40c3-ac80-e2b47c490680/EBRAINS-A5-Brochure.pdf\n",
            "https://files.ebrains.eu/file/e4b05476-d2f0-49c2-8b45-41f9c317892e/EBRAINS_AISBL_Access_Policy_04_2022_85c8e61216.pdf\n",
            "https://files.ebrains.eu/file/e4b05476-d2f0-49c2-8b45-41f9c317892e/EBRAINS_Data_Provision_Protocol_dfe0dcb104.pdf\n",
            "https://files.ebrains.eu/file/e4b05476-d2f0-49c2-8b45-41f9c317892e/EBRAINS_Data_Use_Agreement_90858e7836_ef3ee29d50.pdf\n",
            "https://files.ebrains.eu/file/e4b05476-d2f0-49c2-8b45-41f9c317892e/EBRAINS_General_Terms_of_use_e457353c1a_d2122f84c2.pdf\n",
            "https://files.ebrains.eu/file/e4b05476-d2f0-49c2-8b45-41f9c317892e/EBRAINS_Privacy_Statement_2022_80958229c5.pdf\n",
            "https://files.ebrains.eu/file/e4b05476-d2f0-49c2-8b45-41f9c317892e/EBRAINS_Website_Cookie_Statement_2022_3119732739.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf_url(pdf_url):\n",
        "    response = requests.get(pdf_url)\n",
        "    if response.status_code == 200:\n",
        "        # Use BytesIO to load the PDF content in memory without saving it\n",
        "        pdf_content = BytesIO(response.content)\n",
        "\n",
        "        pdf_document = fitz.open(stream=pdf_content, filetype=\"pdf\")\n",
        "\n",
        "        pdf_text = \"\"\n",
        "        for page_num in range(pdf_document.page_count):\n",
        "            page = pdf_document.load_page(page_num)  # Load each page\n",
        "            pdf_text += page.get_text()  # Extract text from the page\n",
        "\n",
        "        pdf_document.close()  # Close the PDF\n",
        "        return pdf_text\n",
        "    else:\n",
        "        print(f\"Failed to retrieve PDF from {pdf_url}\")\n",
        "        return None\n",
        "\n",
        "pdf_url = 'https://files.ebrains.eu/file/1915ab0c-b800-46ca-b433-75f0e7d07dcf/ProjectCommunicationsContentOfficer-Posting.pdf'\n",
        "pdf_text = extract_text_from_pdf_url(pdf_url)\n",
        "\n",
        "if pdf_text:\n",
        "    print(\"Extracted PDF text:\")\n",
        "    print(pdf_text)  # Print the first 1000 characters of the PDF text"
      ],
      "metadata": {
        "id": "sPRcJDRjXqYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def process_pdf_text(pdf_text):\n",
        "    # Step 1: Remove extra newlines and replace them with spaces\n",
        "    # processed_text = pdf_text.replace('\\n', ' ').replace('\\r', ' ')\n",
        "\n",
        "    # Step 2: Remove extra spaces (more than one space in a row)\n",
        "    processed_text = re.sub(r'\\s+', ' ', pdf_text).strip()\n",
        "\n",
        "    # Step 3: Optional - Remove specific unwanted patterns like \"Page X of Y\" if present\n",
        "    # Example: Remove occurrences of \"Page X of Y\"\n",
        "    processed_text = re.sub(r'Page \\d+ of \\d+', '', processed_text)\n",
        "\n",
        "    # Step 4: Optional - Remove other patterns, such as timestamps, headers, or footers\n",
        "    # Example: Remove timestamps like [00:12:34]\n",
        "    processed_text = re.sub(r'\\[\\d{2}:\\d{2}:\\d{2}\\]', '', processed_text)\n",
        "\n",
        "    return processed_text\n",
        "\n",
        "# Example use with extracted PDF text\n",
        "pdf_url = 'https://files.ebrains.eu/file/1915ab0c-b800-46ca-b433-75f0e7d07dcf/ProjectCommunicationsContentOfficer-Posting.pdf'\n",
        "pdf_text = extract_text_from_pdf_url(pdf_url)\n",
        "\n",
        "if pdf_text:\n",
        "    # Process the extracted text\n",
        "    clean_text = process_pdf_text(pdf_text)\n",
        "\n",
        "    # Output the cleaned text\n",
        "    print(\"Processed PDF text:\")\n",
        "    print(clean_text)  # Print first 1000 characters of the cleaned text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4pILYzbYYf6",
        "outputId": "3a3541c8-2317-49d3-e652-cd580d83f29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed PDF text:\n",
            "EBRAINS, International non-profit association, Chaussée de la Hulpe 166, “Glaverbel”, First Floor, Section B, 1170 Brussels, Belgium Company registration number 0740.908.863 - VAT BE 0740.908.863 | Banque/Bank/Bank Account: IBAN: BE31 7360 6257 3855-BIC: KREDBEBB www.ebrains.eu @EBRAINS_eu EBRAINS PROJECT COMMUNICATIONS & CONTENT OFFICER EBRAINS is a European digital research infrastructure for brain research developed by the EC-funded Human Brain Project. Its ambition is to be an enabler of brain science in Europe, offering state-of-the art resources of data, models, tools and computing platforms to the scientific community. In order to build EBRAINS’ presence and profile among the scientific community at large and the wider public in Europe and other parts of the world, EBRAINS is looking for a Project Communications & Content Officer. EBRAINS is currently further developing its Open Science Tools offering, gaining maturity and robustness, improving its user experience, and broadening the community of neuroscientists and developers who benefit from its resources. In 2021, EBRAINS was added to the ESFRI Roadmap for Research Infrastructures and now also aims to expand collaborations with other EU research infrastructures. The EBRAINS AISBL is a non-profit association and coordinates the operation of the EBRAINS European research infrastructure on behalf of its members. You will be mainly active in defining content and (digital) media priorities and in coordinating these activities while being also involved in all workflows and contributing to the broader EBRAINS communications activities when required. The position reports to EBRAINS Communications Manager and is based in Brussels. Responsibilities • Write engaging content based on the research powered by EBRAINS that appeals to various target audiences and is adapted to the medium through which it is communicated (e.g., website, social media, newsletters, corporate presentations, events) • Identify stories opportunities coming from our partners, researchers, and users • Support the monitoring and reporting of communications plans • Coordinate communications projects with external partners or service providers • Support the website updates • Collaborate for the development of dissemination material for EBRAINS (e.g. podcasts, videos, visuals) • Prospect, segment, and target lead lists by industry or specific characteristics to aid in campaigning efforts • Support various dissemination tasks of EU-funded research projects Qualifications • Hold a bachelor’s degree (minimum) in a natural science related to EBRAINS’ areas of research and/or in Marketing, Communications, Science Communication, Journalism or English Language and Literature • 3-5 years of communications experience, preferable in science journalism or press departments of research-related organisations • Very strong English language skills, both written and spoken. Native English level is a plus • Stellar writing skills and track record of drafting science-communication content for different communications channels (e.g., website, social media, press releases) • Experience in the research, health, or med-tech sector is a plus • A can-do attitude, eagerness to grow and to learn, and will do so proactively by own initiative through the guidance of manager and team members • Good command of MS Office (Word, Excel, and PowerPoint), Adobe Suite (InDesign, Photoshop, Premier) EBRAINS, International non-profit association, Chaussée de la Hulpe 166, “Glaverbel”, First Floor, Section B, 1170 Brussels, Belgium Company registration number 0740.908.863 - VAT BE 0740.908.863 | Banque/Bank/Bank Account: IBAN: BE31 7360 6257 3855-BIC: KREDBEBB www.ebrains.eu @EBRAINS_eu EBRAINS • Digital skills (social media management platforms, Google Analytics, media monitoring software, CRM, CMS…) • Have attention to detail, multitask and deliver on time • Practical, proactive, team player with a positive attitude Why work at the EBRAINS AISBL? Understanding the human brain is one of the greatest challenges facing 21st century science. Joining the EBRAINS AISBL will put you at the centre of an effort to gain profound insights into the structure and functioning of the brain, develop new treatments for brain diseases and build revolutionary new computing technologies. The EBRAINS AISBL team plays a central role in the EBRAINS research infrastructure in Europe and worldwide. You will find yourself inspired by the exciting things that people in the project are building and make a meaningful contribution to understanding the brain. We strive to find the right people and to keep our skills and insights sharp. We are a young, dynamic, interdisciplinary and international team. We focus on delivering high value to the scientific community and are involved in everything from community engagement to integrating scientific workflows with some of the world’s largest supercomputers. Work in the team involves open feedback, with opportunities for additional training to improve our skills. Join us and make an important contribution to the success of one of the most exciting projects of the 21st century! Start date: as soon as possible. Activity rate: 100% Duration of contract: 2 years Applicants should submit a motivation letter and a detailed CV in a single PDF format only, with file name “Surname_position applied_motivation letter and CV” electronically to jobs@ebrains.eu. Please use the position title in the “subject” field. Applications that do not comply with this request will not be considered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_ebrains_links(ebrains_links, output_file=\"ebrains_dataset_no_processing.txt\"):\n",
        "    for url in ebrains_links:\n",
        "        try:\n",
        "            print(f\"Scraping URL: {url}\")\n",
        "            # Send a GET request to the URL\n",
        "            response = requests.get(url)\n",
        "\n",
        "            if response.status_code != 200:\n",
        "                print(f\"Failed to retrieve {url}. Status code: {response.status_code}\")\n",
        "                continue  # Skip to the next URL\n",
        "\n",
        "            # Parse the HTML content using BeautifulSoup\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            # Append the URL as a header in the output file\n",
        "            with open(output_file, \"a\", encoding=\"utf-8\") as file:\n",
        "                for tag in soup.find_all(['p', 'div', 'h1', 'h2', 'h3']):\n",
        "                    if tag.name == 'div':\n",
        "                        for p_tag in tag.find_all('p'):\n",
        "                            file.write(p_tag.get_text().strip() + \"\\n\")\n",
        "                    else:\n",
        "                        file.write(tag.get_text().strip() + \"\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while scraping {url}: {e}\")"
      ],
      "metadata": {
        "id": "5KaghPji-0I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "COFKUNATmErA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Provided data\n",
        "max_words_values = [10, 10, 10, 50, 50, 50, 250, 75, 85, 86, 87, 100]\n",
        "top_k_values = [1, 2, 3, 1, 2, 3, 1, 1, 1, 1, 1, 1]\n",
        "words_in_context_values = [54, 70, 206, 54, 190, 227, 223, 54, 54, 54, 87, 87]\n",
        "\n",
        "# Convert data to a DataFrame format for easy plotting\n",
        "data = pd.DataFrame({\n",
        "    'max_words': max_words_values,\n",
        "    'top_k': top_k_values,\n",
        "    'words_in_context': words_in_context_values\n",
        "})\n",
        "\n",
        "# Plot a bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=data, x='top_k', y='words_in_context', hue='max_words')\n",
        "plt.xlabel(\"top_k\")\n",
        "plt.ylabel(\"words_in_context\")\n",
        "plt.title(\"Number of retrieven words for the context by top_k and max_words in a chunk\")\n",
        "plt.legend(title=\"max_words\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gi6QV196Mbwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Provided data\n",
        "max_words_values = [10, 10, 10, 50, 50, 50, 250, 75, 85, 86, 87, 100]\n",
        "top_k_values = [1, 2, 3, 1, 2, 3, 1, 1, 1, 1, 1, 1]\n",
        "words_in_context_values = [54, 70, 206, 54, 190, 227, 223, 54, 54, 54, 87, 87]\n",
        "\n",
        "# Convert data to a DataFrame format for easy plotting\n",
        "data = pd.DataFrame({\n",
        "    'max_words': max_words_values,\n",
        "    'top_k': top_k_values,\n",
        "    'words_in_context': words_in_context_values\n",
        "})\n",
        "# Create a dictionary to map (top_k, max_words) to words_in_context\n",
        "data_dict = {}\n",
        "\n",
        "for top_k, max_words, words_in_context in zip(top_k_values, max_words_values, words_in_context_values):\n",
        "    data_dict[(top_k, max_words)] = words_in_context\n",
        "\n",
        "# Display the dictionary\n",
        "print(data_dict)\n",
        "\n",
        "# Plot a bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax = sns.barplot(data=data, x='top_k', y='words_in_context', hue='max_words', width=0.9)\n",
        "\n",
        "# Labeling\n",
        "plt.xlabel(\"top_k\")\n",
        "plt.ylabel(\"words_in_context\")\n",
        "plt.title(\"Number of retrieven words for the context by top_k and max_words in a chunk\")\n",
        "plt.legend(title=\"max_words\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f2gsam6bSQso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Provided data\n",
        "max_words_values = [10, 50, 75, 85, 86, 87, 100, 250]\n",
        "top_k_values = [1, 1, 1, 1, 1, 1, 1, 1]\n",
        "words_in_context_values = [54, 54, 54, 54, 54, 87, 87, 223]\n",
        "\n",
        "# Convert data to a DataFrame format for easy plotting\n",
        "data = pd.DataFrame({\n",
        "    'max_words': max_words_values,\n",
        "    'top_k': top_k_values,\n",
        "    'words_in_context': words_in_context_values\n",
        "})\n",
        "\n",
        "# Plot a bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax = sns.barplot(data=data, x='top_k', y='words_in_context', hue='max_words', width=0.9)\n",
        "\n",
        "# Labeling\n",
        "plt.xlabel(\"top_k\")\n",
        "plt.ylabel(\"words_in_context\")\n",
        "plt.title(\"Number of retrieven words for the context by top_k and max_words in a chunk\")\n",
        "plt.legend(title=\"max_words in a chunk\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SA-FxMOUU5dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install faiss-cpu\n",
        "!pip install sentence_transformers\n",
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "!pip install pymupdf\n",
        "from google.colab import files\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "TnmvsYzvJ165"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()  # Here you can upload the dataset\n",
        "\n",
        "print(\"Files in current directory:\")\n",
        "print(os.listdir())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "0d9KoalvSoPz",
        "outputId": "3c7792c2-d816-47b6-ae82-daf12f510c39"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-37e5f0d1-8b4e-4999-b36c-0bd98752c4bc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-37e5f0d1-8b4e-4999-b36c-0bd98752c4bc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset_manually_final_processed.txt to dataset_manually_final_processed (1).txt\n",
            "Files in current directory:\n",
            "['.config', 'dataset_manually_final.txt', 'dataset_manually_final_processed.txt', 'dataset_manually_final_processed (1).txt', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate bitsandbytes\n",
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "5GQ1OZE_TfMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "# Load the text file\n",
        "# with open(\"dataset_manually_06_11.txt\", \"r\") as file:\n",
        "#with open(\"dataset_manually_final.txt\", \"r\") as file:\n",
        "with open(\"dataset_manually_final_processed.txt\", \"r\") as file:\n",
        "  text = file.read()\n",
        "\n",
        "# Basic splitting into chunks\n",
        "def split_text_into_chunks_with_overlap(text, max_words, overlap_words):\n",
        "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for sentence in sentences:\n",
        "        words = sentence.split()\n",
        "        if current_length + len(words) > max_words:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            overlap = current_chunk[-overlap_words:] if overlap_words < len(current_chunk) else current_chunk\n",
        "            current_chunk = overlap[:]  # Start new chunk with overlap\n",
        "            current_length = sum(len(s.split()) for s in current_chunk)  # Set the length to overlap length\n",
        "\n",
        "        current_chunk.append(sentence)\n",
        "        current_length += len(words)\n",
        "    chunks.append(\" \".join(current_chunk))  # Add the last chunk\n",
        "    return chunks\n",
        "\n",
        "def split_text_into_chunks(text, max_words):\n",
        "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for sentence in sentences:\n",
        "        words = sentence.split()\n",
        "        if current_length + len(words) > max_words:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "        current_chunk.append(sentence)\n",
        "        current_length += len(words)\n",
        "    chunks.append(\" \".join(current_chunk))  # Add the last chunk\n",
        "    return chunks\n",
        "\n",
        "max_words=50\n",
        "overlap_words=5\n",
        "if overlap_words == 0:\n",
        "  print(\"No overlap\")\n",
        "  chunks = split_text_into_chunks(text, max_words)\n",
        "else:\n",
        "  print(\"Overlap\")\n",
        "  chunks = split_text_into_chunks_with_overlap(text, max_words,overlap_words)\n",
        "\n",
        "# Load the sentence transformer model\n",
        "model1 = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "#model1 = SentenceTransformer('paraphrase-MPNet-base-v2')\n",
        "#model1 = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
        "# Encode the chunks into embeddings\n",
        "chunk_embeddings = model1.encode(chunks)\n",
        "\n",
        "# Create a FAISS index\n",
        "embedding_dimension = chunk_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(embedding_dimension)\n",
        "index.add(np.array(chunk_embeddings))\n",
        "\n",
        "# Retrieve all vectors from the FAISS index\n",
        "# stored_vectors = index.reconstruct_n(0, index.ntotal)\n",
        "\n",
        "# Print the vectors\n",
        "# print(\"Vectors stored in the FAISS index:\")\n",
        "# print(stored_vectors)\n",
        "\n",
        "def retrieve_relevant_chunks(query, index, chunks, model, top_k):\n",
        "    query_embedding = model1.encode([query])\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "    return [chunks[idx] for idx in indices[0]]\n",
        "\n",
        "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
        "\n",
        "# Load a pre-trained model and tokenizer\n",
        "tokenizer_llm_1 = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model_llm_1 = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased-distilled-squad')\n",
        "model_llm_1.eval()\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_llm_1.to(device)\n",
        "\n",
        "#query = \"What is the virtual brain?\"\n",
        "query = \"what is EBRAINS Monkey Brain Atlas?\"\n",
        "#query3 = \"Tell me something about EBRAINS Knowledge Graph (KG)\"\n",
        "# For more information or to inquire about accessing HPC resources, please visit our collaboratory wiki or us via base-infra-resources@ebrains.eu.\n",
        "# Where can I find more information about HPC resources\n",
        "# NEST Desktop\n",
        "top_k = 1\n",
        "relevant_chunks = retrieve_relevant_chunks(query, index, chunks, model1, top_k)\n",
        "#print(\"Relevant chunks: \")\n",
        "#rint(relevant_chunks)\n",
        "\n",
        "# Format retrieved chunks as context\n",
        "context = \" \".join(relevant_chunks)\n",
        "num_words_in_context = len(context.split())\n",
        "\n",
        "def generate_response(query):\n",
        "\n",
        "    # Tokenize inputs\n",
        "    inputs = tokenizer_llm_1(\n",
        "        query,\n",
        "        context,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=512,  # Set the maximum sequence length\n",
        "        truncation=True,  # Truncate if the sequence is longer\n",
        "    ).to(device)\n",
        "    # return context\n",
        "\n",
        "    # Get model predictions\n",
        "    outputs = model_llm_1(**inputs)\n",
        "    start_logits = outputs.start_logits\n",
        "    end_logits = outputs.end_logits\n",
        "\n",
        "    # Find the start and end positions of the answer\n",
        "    start_index = start_logits.argmax()\n",
        "    end_index = end_logits.argmax()\n",
        "\n",
        "    # Decode the answer\n",
        "    answer = tokenizer_llm_1.convert_tokens_to_string(tokenizer_llm_1.convert_ids_to_tokens(inputs.input_ids[0][start_index:end_index+1]))\n",
        "    return answer\n",
        "\n",
        "llm_response = generate_response(query)\n",
        "print(llm_response)\n",
        "# Prepare input text with relevant context and query as before\n",
        "input_text = f\"Chosen Model: {model1}\\nMax words: {max_words}\\nValue of k: {top_k}\\nOverlap words: {overlap_words}\\nQuestion: {query}\\nWords in context: {num_words_in_context}\\nRetrieven context: {context}\"\n",
        "print(input_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL0JVeibjdJj",
        "outputId": "2d88509f-5e7e-4f24-baf9-3a869cb46c8a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overlap\n",
            "a comprehensive resource that provides in - depth insights into the anatomy , connectivity , and functions of the macaque monkey brain\n",
            "Chosen Model: SentenceTransformer(\n",
            "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
            "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
            "  (2): Normalize()\n",
            ")\n",
            "Max words: 50\n",
            "Value of k: 1\n",
            "Overlap words: 5\n",
            "Question: what is EBRAINS Monkey Brain Atlas?\n",
            "Words in context: 148\n",
            "Retrieven context: The atlas s multiple reference spaces, including the MNI Colin27, ICBM 152 2009c and average spaces which are common in functional imaging and whole-brain connectivity studies. It integrates these with the microscopic resolution BigBrain model as a link from the macroscopic to the cellular scale. Brain regions are characterised by multiple levels of brain connectivity and multimodal regional measurements including neurotransmitter receptor densities, cell densities, fiber orientations, genomics and physiological data. The EBRAINS Monkey Brain Atlas is a comprehensive resource that provides in-depth insights into the anatomy, connectivity, and functions of the macaque monkey brain. It includes detailed information about the organization of the monkey brain at multiple levels, ranging from the microscopic level to the macroscopic level of the entire brain. The multilevel macaque brain builds on the MEBRAINS Template, a nonlinear symmetric population-based monkey template which reflects the macroanatomical scale as a unifying principle of organization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"meta-llama/Llama-3.2-1B\"\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
        "\n",
        "# Generate text\n",
        "inputs = tokenizer(\"how are you\", return_tensors=\"pt\").to(model.device)\n",
        "outputs = model.generate(**inputs)\n",
        "\n",
        "# Decode and print the generated output\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC0kG_NaSNvs",
        "outputId": "15573996-1f1a-40f2-96a8-a55cbe887b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "how are you doing? I hope you are doing well. I am also writing a blog post\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove redundant sentences\n",
        "def remove_redundant_sentences(input_file, output_file):\n",
        "    try:\n",
        "        # Read the content of the file\n",
        "        with open(input_file, 'r') as file:\n",
        "            text = file.read()\n",
        "\n",
        "        # Split the text into sentences\n",
        "        sentences = text.split('.')\n",
        "\n",
        "        # Remove leading and trailing whitespaces from each sentence\n",
        "        cleaned_sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
        "\n",
        "        # Use a set to remove duplicates while preserving order\n",
        "        seen = set()\n",
        "        unique_sentences = []\n",
        "        for sentence in cleaned_sentences:\n",
        "            if sentence not in seen:\n",
        "                seen.add(sentence)\n",
        "                unique_sentences.append(sentence)\n",
        "\n",
        "        # Join unique sentences back into a single string with a period\n",
        "        result_text = '. '.join(unique_sentences) + '.'\n",
        "\n",
        "        # Write the cleaned text to the output file\n",
        "        with open(output_file, 'w') as file:\n",
        "            file.write(result_text)\n",
        "\n",
        "        print(f\"Redundant sentences removed. Cleaned text written to '{output_file}'.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{input_file}' not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Usage Example\n",
        "input_file = 'dataset_manually_final.txt'  # Replace with your input file name\n",
        "output_file = 'dataset_manually_final_processed.txt'  # Replace with your desired output file name\n",
        "\n",
        "remove_redundant_sentences(input_file, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-lrRrABzEHO",
        "outputId": "35ffa595-c0a3-487a-ec34-ed50717201dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Redundant sentences removed. Cleaned text written to 'dataset_manually_final_processed.txt'.\n"
          ]
        }
      ]
    }
  ]
}